from copy import deepcopy

import torch 
from torch import nn 
from torch.autograd import Variable
from torch.distributed import rpc

from .embedders import GCN 
from .euler_interface import Euler_Embed_Unit, Euler_Encoder, Euler_Recurrent
from .softmax_det import TEdgeAnoms
from .utils import _remote_method_async


# From Ramesh's paper, this is f(u,v,N(u))
class TEdgeAnomsPredictor(TEdgeAnoms):
    def inner_forward(self, x, ei):
        # Loss is a little more complicated now, so we calculate it sepearately
        return self.H(x,ei)
        
    def loss_fn(self, H, ei):
        '''
        Assumes H is aligned w ei s.t. H[0] represents embeddings from
        timestep 0 and ei[0] represents edges at timestep 1
        '''
        dists = self.W(H)
        return self.ce_loss(
            dists[ei[0]],
            ei[1]
        )


'''
Attempting strat from this paper:
Unified Graph Embedding-based Anomalous Edge Detection
https://ieeexplore.ieee.org/document/9206720
'''
class TEdgeConvPredictor(GCN):
    def __init__(self, data_load, data_kws, h_dim, z_dim, n_samples=5):
        super().__init__(data_load, data_kws, h_dim, z_dim)
        
        # This is a hacky solution. TODO figure out how to tell edge conv number of 
        # output dimensions from GRU
        self.anom_detector = TEdgeAnomsPredictor(z_dim//2, self.data.num_nodes, n_samples)

    def score(self, H, ei):
        return self.anom_detector.score(H, ei)

    def anom_loss(self, H, ei):
        return self.anom_detector.loss_fn(H, ei)


def pred_tedge_rref(loader, kwargs, h_dim, z_dim, head=False):
    return TEdgeEncoderPredictor(
        TEdgeConvPredictor(loader, kwargs, h_dim, z_dim), head
    )

class TEdgeEncoderPredictor(Euler_Encoder):
    def __init__(self, module: Euler_Embed_Unit, head: bool, **kwargs):
        '''
        Constructor for PredictorEncoder

        parameters 
        ----------
        module : Euler_Embed_Unit
            The model to encode temporal data. module.forward must accept an enum 
            reprsenting train/val/test and nothing else. See embedders.py for acceptable
            modules 
        head : boolean 
            If this worker holds timestep 0, which will never be encoded, as Predictor modules
            aim to predict future snapshots, it needs to know not to run loss on snapshot[0]
        kwargs : dict
            any args for the DDP constructor
        '''

        super().__init__(module, **kwargs)
        self.is_head = 1 if head else 0
        if self.is_head:
            print("%s is head" % rpc.get_worker_info().name)


    def detect_anoms(self, zs, partition, no_grad):
        '''
        Generates H embeds for anom detection
        '''
        H = []
        
        for i in range(self.module.data.T):
            ei = self.module.data.ei_masked(partition, i)
            h = self.module.anom_detector(zs[i], ei, no_grad=no_grad)
            H.append(h)

        return torch.stack(H)

    def score_edges(self, H, partition, nratio):
        n = self.module.data.get_negative_edges(partition, nratio)

        p_scores = []
        n_scores = []

        for i in range(self.is_head, self.module.data.T):
            p = self.module.data.ei_masked(partition, i)
            if p.size(1) == 0:
                continue

            p_scores.append(self.module.score(H[i], p))
            n_scores.append(self.module.score(H[i], n[i]))

        p_scores = torch.cat(p_scores, dim=0)
        n_scores = torch.cat(n_scores, dim=0)

        return p_scores, n_scores

    def decode_all(self, H, unsqueeze=False):
        '''
        Given node embeddings, return edge likelihoods for 
        all subgraphs held by this model
        
        For Predictor model, assume we are given embeddings 
        for timesteps -1 to N-1 (where Z_{-1} is a dummy value
        to be ignored if this is worker 0) with which to predict
        E_1 to E_N

        zs : torch.Tensor
            A T x d x N tensor of node embeddings generated by the models, 
            it is safe to assume z[n] are the embeddings for nodes in the 
            snapshot held by this model's TGraph at timestep n
        '''
        preds, ys, cnts = [], [], []
        for i in range(self.is_head, self.module.data.T):
            preds.append(
                self.module.score(
                    H[i],
                    self.module.data.eis[i]
                )
            )

            ys.append(self.module.data.ys[i])
            cnts.append(self.module.data.cnt[i])

        return preds, ys, cnts

    def calc_loss(self, z, H, partition, nratio):
        '''
        Want the Z embeddings to do static prediction (ie Z[0] reconstructs ei[0])
        Want the anom detector to predict next timestep (ie H[0] predicts ei[1])

        Thus, we assume the H embeds are offset already, and if head, H[0] is a dummy value
        '''
        recon_loss = torch.zeros(1)
        anom_loss = torch.zeros(1)
        ns = self.module.data.get_negative_edges(partition, nratio)

        for i in range(len(z)):
            ps = self.module.data.ei_masked(partition, i)
            
            # Edge case. Prevents nan errors when not enough edges
            # only happens with very small timewindows 
            if ps.size(1) == 0:
                continue

            recon_loss += self.bce(
                self.decode(ps, z[i]),
                self.decode(ns[i], z[i])
            )
            
            # Cant predict ei[0] as anom detector only predicts future
            # time steps
            if self.is_head:
                if i > 0:
                    anom_loss += self.module.anom_loss(H[i], ps)
            else:
                anom_loss += self.module.anom_loss(H[i], ps)

        tot_loss = recon_loss.true_divide(len(z)) 

        if len(z)-self.is_head:
            tot_loss += anom_loss.true_divide(len(z)-self.is_head)

        return tot_loss


class TEdgeRecurrentPredictor(Euler_Recurrent):
    def forward(self, mask_enum, include_h=False, h0=None, no_grad=False):
        if include_h:
            z, h = super().forward(mask_enum, include_h=include_h, h0=h0, no_grad=no_grad)
        else:
            z = super().forward(mask_enum, include_h=include_h, h0=h0, no_grad=no_grad)

        # Train the anomaly detector on the output of the embedder at the same time 
        # note the Variable though; loss here won't backprop into the GNN/RNN
        futs = []
        start = 0
        for i in range(self.num_workers):
            end = start + self.len_from_each[i]
            futs.append(
                _remote_method_async(
                    TEdgeEncoderPredictor.detect_anoms,
                    self.gcns[i],
                    Variable(z[start : end]), 
                    mask_enum,
                    no_grad
                )
            )
            start = end 

        H = [f.wait() for f in futs]
        H = torch.cat(H, dim=0)
        
        # Align H[0] to predict G[1], and trim off extra value at the end
        H = torch.cat([
            torch.zeros(H[0].size()).unsqueeze(0),
            H[:-1]
        ])

        # Finally, split into parts for calculating loss/scores later
        self.H = []
        start = 0
        for i in range(self.num_workers):
            end = start + self.len_from_each[i]
            self.H.append(H[start:end])
            start = end 

        if include_h:
            return z, h 
        else: 
            return z

    def score_all(self, *args, unsqueeze=False):
        '''
        Has the distributed models score and label all of their edges
        Sends workers embeddings such that H[n] is used to reconstruct graph at 
        snapshot n

        H : torch.Tensor 
            A T x d x N tensor of node embeddings generated by each graph snapshot
            Need to offset according to how far in the future embeddings are supposed
            to represent.
        '''
        futs = [
            _remote_method_async(
                TEdgeEncoderPredictor.decode_all,
                self.gcns[i],
                self.H[i],
                unsqueeze=unsqueeze
            )
        for i in range(self.num_workers) ]

        obj = [f.wait() for f in futs]
        scores, ys, cnts = zip(*obj)
        
        # Compress into single list of snapshots
        scores = sum(scores, [])
        ys = sum(ys, [])
        cnts = sum(cnts, [])

        return scores, ys, cnts


    def loss_fn(self, zs, partition, nratio=1):
        '''
        Runs NLL on each worker machine given the generated embeds
        Sends workers embeddings such that zs[n] is used to reconstruct graph at 
        snapshot n

        zs : torch.Tensor 
            A T x d x N tensor of node embeddings generated by each graph snapshot
            Need to offset according to how far in the future embeddings are supposed
            to represent.
        partition : int
            enum representing train, validation, test sent to workers
        nratio : float
            The workers sample nratio * |E| negative edges for calculating loss
        '''
        futs = []
        start = 0
    
        for i in range(self.num_workers):
            end = start + self.len_from_each[i]
            futs.append(
                _remote_method_async(
                    TEdgeEncoderPredictor.calc_loss,
                    self.gcns[i],
                    zs[start : end],
                    self.H[i],
                    partition, nratio
                )
            )
            start = end 

        return [f.wait() for f in futs]
        

    def score_edges(self, zs, partition, nratio=1):
        '''
        Gets edge scores from dist modules, and negative edges. 
        Sends workers embeddings such that zs[n] is used to reconstruct graph at 
        snapshot n

        zs : torch.Tensor 
            A T x d x N tensor of node embeddings generated by each graph snapshot
            Need to offset according to how far in the future embeddings are supposed
            to represent.
        partition : int
            enum representing train, validation, test sent to workers
        nratio : float
            The workers sample nratio * |E| negative edges for calculating loss
        '''
    
        futs = [
            _remote_method_async(
                TEdgeEncoderPredictor.score_edges,
                self.gcns[i],
                self.H[i], 
                partition, nratio
            )
        for i in range(self.num_workers) ]

        pos, neg = zip(*[f.wait() for f in futs])
        return torch.cat(pos, dim=0), torch.cat(neg, dim=0)
    